{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Australian Data with LRMoE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will fit the Australian automobile data `ausprivauto0405` available in the `CASdatasets` [R package](http://cas.uqam.ca/).\n",
    "We compare the performance of LRMoE mixture of Poisson distributions with the standard Poisson Generalized Linear Model (GLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson\n",
    "@quickactivate \"LRMoEjl Demo\"\n",
    "\n",
    "using CategoricalArrays, DataFrames, Distributions\n",
    "using GLM, LRMoE, JLD2, PrettyTables, Random, StatsPlots\n",
    "\n",
    "# some helper functions are hidden in a separate source file\n",
    "include(srcdir(\"2023-CAS-Australian-util.jl\"))\n",
    "using .australian_auto_util_jl:\n",
    "    load_aus_auto_jld,\n",
    "    generate_aus_auto_LRMoE_data,\n",
    "    predict_aus_auto_glm_distribution,\n",
    "    predict_aus_auto_LRMoE_distribution,\n",
    "    generate_pmf_comparison,\n",
    "    plot_pmf_comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the dataset is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_aus_auto_jld()\n",
    "println(\"Number of observations: $(nrow(df))\")\n",
    "println(\"Sample rows of the data:\")\n",
    "pretty_table(first(df, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Distribution of claim frequency:\")\n",
    "df_claim_summary = combine(groupby(df, :ClaimNb),\n",
    "    :ClaimNb => length => :ClaimNb_Count)\n",
    "df_claim_summary.ClaimNb_Freq = df_claim_summary.ClaimNb_Count ./ sum(df_claim_summary.ClaimNb_Count)\n",
    "pretty_table(df_claim_summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: Poisson GLM\n",
    "\n",
    "We consider the Poisson GLM with the following covariates: `Gender`, `DrivAge`, `VehAge` and `VehValue`, with\n",
    "the logarithm of `Exposure` also incorporated to predict the claim frequency `ClaimNb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fml_ClaimNb = @formula(ClaimNb ~  Gender + DrivAge + VehAge + VehValue)\n",
    "glm_model = glm(fml_ClaimNb, df, Poisson(), LogLink(); offset=log.(df.Exposure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Fitted Loglikelihood: $(GLM.loglikelihood(glm_model))\")\n",
    "println(\"AIC: $(GLM.aic(glm_model))\")\n",
    "println(\"BIC: $(GLM.bic(glm_model))\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRMoE with Poisson Experts\n",
    "\n",
    "We also consider fitting a 3-component LRMoE mixture of Poisson distributions with the same covariates as above.\n",
    "The first step is to convert the original dataframe in to matrix formats\n",
    "(support for the `@formula` interface is a feature under development)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to matrix format for model fitting\n",
    "y, X, y_col, X_col = generate_aus_auto_LRMoE_data(fml_ClaimNb, df)\n",
    "exposure = df.Exposure\n",
    "# view the converted data\n",
    "println(\"First row of y: $(y[1, :])\")\n",
    "println(\"First row of X: $(X[1, :])\")\n",
    "println(\"Column names of X: $(X_col)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LRMoE.jl` package provides a function for initializing a model, wihch provides initial\n",
    "values `α_init` for the logit regression parameters and `params_init` for all possible expert functions.\n",
    "We can pick out the Poisson initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random.seed!(20230315)\n",
    "Random.seed!(42)\n",
    "n_comp = 3\n",
    "model_init = cmm_init(y, X, n_comp, [\"discrete\"]; exact_Y = true, n_random = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickout desired parameter initializations\n",
    "α_init = model_init.α_init\n",
    "experts_init = vcat([hcat([model_init.params_init[1][j][1] for j in 1:n_comp]...) for d in 1:1]...)\n",
    "# view\n",
    "println(\"α_init: $(α_init)\")\n",
    "println(\"experts_init: $(experts_init[1, :])\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model initialization provided by the default function typically performs well.\n",
    "Sometimes, we may also want to provide our own initializations given some domain knowledge and prior beliefs.\n",
    "For example, if we believe the portfolio consists of high-, mid- and low-risk subgroups, the experts can be initialized as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts_init_customized = [PoissonExpert(0.30);; PoissonExpert(0.10);; PoissonExpert(0.05)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several settings to control the fitting function. For example, `ϵ` controls when to stop the EM algorithm based on the increment in loglikelihood, while `ecm_iter_max` provides a hard stop after a certain number of iterations. More details can be found in the package [documentation](https://actsci.utstat.utoronto.ca/LRMoE.jl/stable/fit/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRMoE_model = fit_LRMoE(y, X, α_init, experts_init_customized;\n",
    "    exposure=exposure, exact_Y=true, ϵ=0.01, ecm_iter_max=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(LRMoE_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted LRMoE model shows better loglikelihood and AIC values than the Poisson GLM. It can be saved in the `JLD2` format for further analysis (see also the documentations [here](https://juliaio.github.io/JLD2.jl/stable/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a fitted model\n",
    "jldsave(datadir(\"2023-CAS-demo\", \"aus-auto-LRMoE-model.jld2\"); model=LRMoE_model)\n",
    "# load a fitted model\n",
    "# LRMoE_model = load(datadir(\"2023-CAS-demo\", \"aus-auto-LRMoE-model.jld2\"))[\"model\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Insights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Fitted Distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that LRMoE performs better when fitting the data, but exactly how?\n",
    "This can be investigated by looking at the fitted distributions of Poisson GLM and LRMoE, and comparing then with the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_dist_glm = predict_aus_auto_glm_distribution(glm_model, df)\n",
    "pretty_table(fitted_dist_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pmf_LRMoE = predict_aus_auto_LRMoE_distribution(LRMoE_model.model_fit, X, exposure)\n",
    "pretty_table(fitted_pmf_LRMoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join empirical distribution and fitted distributions\n",
    "# calculate the percentage error\n",
    "df_pmf_comparison = generate_pmf_comparison(df_claim_summary, fitted_dist_glm, fitted_pmf_LRMoE)\n",
    "pretty_table(df_pmf_comparison)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we see that the Poisson GLM fails to capture the tail of the frequency distribution, severely underfitting\n",
    "the probability mass function at 3 and 4+ claims. In contrast, LRMoE is able to capture the entirety of the frequency distribution\n",
    "reasonably well. This can also be visualized by the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pmf_comparison(df_pmf_comparison)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also consider different ways of slicing the portfilio, e.g. by driver's age.\n",
    "The LRMoE model outperforms in each group of drivers with similar ages, especially on the probability of 0, 1, and 2 claims.\n",
    "The fitting result of LRMoE could be further imptoved if we consider an even larger number of latent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for driver_age in levels(df.DrivAge)[1:2]\n",
    "    idx = (df.DrivAge .== driver_age)\n",
    "    df_claim_summary_sub = combine(groupby(df[idx, :], :ClaimNb),\n",
    "        :ClaimNb => length => :ClaimNb_Count)\n",
    "    df_claim_summary_sub.ClaimNb_Freq = df_claim_summary_sub.ClaimNb_Count ./ sum(df_claim_summary_sub.ClaimNb_Count)\n",
    "    fitted_dist_glm_sub = predict_aus_auto_glm_distribution(glm_model, df[idx, :])\n",
    "    fitted_pmf_LRMoE_sub = predict_aus_auto_LRMoE_distribution(LRMoE_model.model_fit, X[idx, :], exposure[idx])\n",
    "    df_pmf_comparison_sub = generate_pmf_comparison(df_claim_summary_sub, fitted_dist_glm, fitted_pmf_LRMoE_sub)\n",
    "    println(\"Driver age: $driver_age, Number of observations: $(sum(idx))\")\n",
    "    pretty_table(df_pmf_comparison_sub)\n",
    "    println(\"\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for driver_age in levels(df.DrivAge)[3:4]\n",
    "    idx = (df.DrivAge .== driver_age)\n",
    "    df_claim_summary_sub = combine(groupby(df[idx, :], :ClaimNb),\n",
    "        :ClaimNb => length => :ClaimNb_Count)\n",
    "    df_claim_summary_sub.ClaimNb_Freq = df_claim_summary_sub.ClaimNb_Count ./ sum(df_claim_summary_sub.ClaimNb_Count)\n",
    "    fitted_dist_glm_sub = predict_aus_auto_glm_distribution(glm_model, df[idx, :])\n",
    "    fitted_pmf_LRMoE_sub = predict_aus_auto_LRMoE_distribution(LRMoE_model.model_fit, X[idx, :], exposure[idx])\n",
    "    df_pmf_comparison_sub = generate_pmf_comparison(df_claim_summary_sub, fitted_dist_glm, fitted_pmf_LRMoE_sub)\n",
    "    println(\"Driver age: $driver_age, Number of observations: $(sum(idx))\")\n",
    "    pretty_table(df_pmf_comparison_sub)\n",
    "    println(\"\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for driver_age in levels(df.DrivAge)[5:6]\n",
    "    idx = (df.DrivAge .== driver_age)\n",
    "    df_claim_summary_sub = combine(groupby(df[idx, :], :ClaimNb),\n",
    "        :ClaimNb => length => :ClaimNb_Count)\n",
    "    df_claim_summary_sub.ClaimNb_Freq = df_claim_summary_sub.ClaimNb_Count ./ sum(df_claim_summary_sub.ClaimNb_Count)\n",
    "    fitted_dist_glm_sub = predict_aus_auto_glm_distribution(glm_model, df[idx, :])\n",
    "    fitted_pmf_LRMoE_sub = predict_aus_auto_LRMoE_distribution(LRMoE_model.model_fit, X[idx, :], exposure[idx])\n",
    "    df_pmf_comparison_sub = generate_pmf_comparison(df_claim_summary_sub, fitted_dist_glm, fitted_pmf_LRMoE_sub)\n",
    "    println(\"Driver age: $driver_age, Number of observations: $(sum(idx))\")\n",
    "    pretty_table(df_pmf_comparison_sub)\n",
    "    println(\"\")\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Groups of Policyholders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the fitted expert functions, we see indeed that policyholders have different levels of risks as measured by the expected number of claims (i.e. the parameter of Poisson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(LRMoE_model.model_fit.comp_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the modelling structure of LRMoE, the covariates will affect the probabilities of each latent risk groups. Let us look at `Gender` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict latent class probabilities by gender\n",
    "idx = (df.Gender .== \"Female\")\n",
    "latent_class_probs_female = predict_class_prior(X[idx, :], LRMoE_model.model_fit.α).prob\n",
    "idx = (df.Gender .== \"Male\")\n",
    "latent_class_probs_male = predict_class_prior(X[idx, :], LRMoE_model.model_fit.α).prob\n",
    "\n",
    "# plot latent class probabilities\n",
    "for j in [1, 2, 3]\n",
    "    fig = plot(size=(750, 500))\n",
    "    plot_min = minimum(vcat(latent_class_probs_male[:, j], latent_class_probs_female[:, j]))\n",
    "    plot_max = maximum(vcat(latent_class_probs_male[:, j], latent_class_probs_female[:, j]))\n",
    "    histogram!(latent_class_probs_male[:, j], label=\"Male\", bins=(plot_min:0.005:plot_max), alpha=0.5, normalize=true)\n",
    "    histogram!(latent_class_probs_female[:, j], label=\"Female\", bins=(plot_min:0.005:plot_max), alpha=0.5, normalize=true)\n",
    "    title!(\"Latent Class $j\")\n",
    "    display(fig)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While both genders share a similar distribution on the probability of Latent Class 1, female drivers tend to be more likely to belong to Latent Class 3, compared with male drivers. This in turn yields a higher prediction of the expected claim frequencies per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (df.Gender .== \"Female\")\n",
    "predicted_mean_female = predict_mean_prior(X[idx, :], LRMoE_model.model_fit.α, LRMoE_model.model_fit.comp_dist)\n",
    "idx = (df.Gender .== \"Male\")\n",
    "predicted_mean_male = predict_mean_prior(X[idx, :], LRMoE_model.model_fit.α, LRMoE_model.model_fit.comp_dist)\n",
    "\n",
    "fig = plot(size=(750, 500))\n",
    "histogram!(predicted_mean_male[:, 1], label=\"Male\", bins=0.10:0.001:0.25, alpha=0.5, normalize=true)\n",
    "histogram!(predicted_mean_female[:, 1], label=\"Female\", bins=0.10:0.001:0.25, alpha=0.5, normalize=true)\n",
    "title!(\"Predicted Mean Frequency\")\n",
    "display(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discrepancy between male and female drivers are also reflected empirically in the actual data, which is captured by the LRMoE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female\n",
    "idx = (df.Gender .== \"Female\")\n",
    "mean_frequency_empirical = sum(df[idx, \"ClaimNb\"]) / sum(df[idx, \"Exposure\"])\n",
    "mean_frequency_GLM = mean(predict(glm_model, df[idx, :], offset=zero(log.(df[idx, \"Exposure\"]))))\n",
    "mean_frequency_LRMoE = mean(predicted_mean_female)\n",
    "println(\"Female Drivers:\")\n",
    "println(\"Empirical mean frequency: $mean_frequency_empirical\")\n",
    "println(\"GLM predicted mean frequency: $mean_frequency_GLM, ($((mean_frequency_GLM-mean_frequency_empirical)/mean_frequency_empirical *100)%)\")\n",
    "println(\"LRMoE predicted mean frequency: $mean_frequency_LRMoE, ($((mean_frequency_LRMoE-mean_frequency_empirical)/mean_frequency_empirical *100)%)\")\n",
    "# Male\n",
    "idx = (df.Gender .== \"Male\")\n",
    "mean_frequency_empirical = sum(df[idx, \"ClaimNb\"]) / sum(df[idx, \"Exposure\"])\n",
    "mean_frequency_GLM = mean(predict(glm_model, df[idx, :], offset=zero(log.(df[idx, \"Exposure\"]))))\n",
    "mean_frequency_LRMoE = mean(predicted_mean_male)\n",
    "println(\"Male Drivers:\")\n",
    "println(\"Empirical mean frequency: $mean_frequency_empirical\")\n",
    "println(\"GLM predicted mean frequency: $mean_frequency_GLM, ($((mean_frequency_GLM-mean_frequency_empirical)/mean_frequency_empirical *100)%)\")\n",
    "println(\"LRMoE predicted mean frequency: $mean_frequency_LRMoE, ($((mean_frequency_LRMoE-mean_frequency_empirical)/mean_frequency_empirical *100)%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
